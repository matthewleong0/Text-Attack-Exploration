{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec59942a",
   "metadata": {},
   "source": [
    "# Text Attack Tensorflow Exporation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6526c81",
   "metadata": {},
   "source": [
    "This notebook explores the text attack module and its recipes against a Tensorflow LSTM model. The vectorizer is a padded sequence. 7 attacks were successfully implemented. The chosen problem set is reviews from rotten tomatoes and the classification task is to label positive or negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa753fda",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "613a1f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, Input, LSTM, SimpleRNN, Conv1D, MaxPool1D, Bidirectional,\\\n",
    "Dropout, MaxPooling1D, Activation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b198a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355ad3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (C:/Users/mattl/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4414fee968c447492d06d19f4db6686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using rotten tomatos IMBD dataset for this\n",
    "dataset = datasets.load_dataset('rotten_tomatoes')\n",
    "\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53455ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for preprocessing\n",
    "def preprocess(row):\n",
    "\n",
    "    row = re.sub('[%\\n]', ' ', row)\n",
    "    row = re.sub('[%’\"\"-+\\,.:<>-]', '', row)\n",
    "    row = row.lstrip('[').rstrip(']')\n",
    "    row = re.sub('[^A-Za-z0-9 ]+','',row)\n",
    "\n",
    "    #lower case and remove white spaces\n",
    "    row = row.lower()\n",
    "    row = row.strip()\n",
    "\n",
    "    #tokenize and remove stopwords\n",
    "    tokens = tokenizer.tokenize(row)\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    lemma = [wnl.lemmatize(w) for w in tokens]\n",
    "    return lemma\n",
    "\n",
    "def rejoin_words(row):\n",
    "    joined_words = ( \" \".join(row))\n",
    "    return joined_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "955e3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and remove stopwords\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# uncomment if need to download\n",
    "#nltk.download(\"stopwords\") \n",
    "#nltk.download('punkt')\n",
    "\n",
    "stop_words =set(stopwords.words(\"english\"))\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "for df in [train_df,test_df]:\n",
    "    df['words'] = df['text'].apply(preprocess)\n",
    "    df['processed'] = df['words'].apply(rejoin_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be3136f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The padded encoding for document\n",
      " rock destined 21st century new conan he going make splash even greater arnold schwarzenegger jeanclaud van damme steven segal \n",
      " is :  [ 480 2493 2933  783   37 5636  212  147    5 2494   10 2171 1193 1719\n",
      " 8188 1296 5637  784 8189    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# tokenize to sequence, padding\n",
    "# get list of all words\n",
    "total_word = []\n",
    "max_len = 0\n",
    "for i in train_df[\"words\"].tolist():\n",
    "    max_len = max(max_len, len(i))\n",
    "    for j in i:\n",
    "        total_word.append(j)\n",
    "total_word = list(set(total_word))\n",
    "\n",
    "# tokenize to sequences\n",
    "tokenizer = Tokenizer(num_words = len(total_word))\n",
    "tokenizer.fit_on_texts(train_df[\"processed\"])\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df[\"processed\"])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df[\"processed\"])\n",
    "\n",
    "# padding\n",
    "padded_train = pad_sequences(train_sequences, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "padded_test = pad_sequences(test_sequences, maxlen = max_len, padding = 'post', truncating = 'post') \n",
    "print(\"The padded encoding for document\\n\",train_df[\"processed\"][0],\"\\n is : \",padded_train[0])\n",
    "\n",
    "# y-values\n",
    "y_train = train_df['label'].values\n",
    "y_test = test_df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559bcd17",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ec0f7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 180)         2957940   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 300)              397200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 300)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               38528     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,393,797\n",
      "Trainable params: 3,393,797\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(total_word), output_dim = 180))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1,activation= 'sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6bac7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "171/171 [==============================] - 19s 94ms/step - loss: 0.5898 - binary_accuracy: 0.6662 - val_loss: 0.5147 - val_binary_accuracy: 0.7420\n",
      "Epoch 2/2\n",
      "171/171 [==============================] - 25s 148ms/step - loss: 0.2828 - binary_accuracy: 0.8832 - val_loss: 0.5237 - val_binary_accuracy: 0.7542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2200ec073d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(padded_train, y_train, batch_size = 50, validation_data = (padded_test, y_test), epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7c1dd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 4s 13ms/step\n",
      "34/34 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_pred_tr_pr = [i[0] for i in model.predict(padded_train)]\n",
    "lstm_pred_te_pr = [i[0] for i in model.predict(padded_test) ]\n",
    "lstm_pred_tr = [int(i>=0.5) for i in lstm_pred_tr_pr]\n",
    "lstm_pred_te = [int(i>=0.5) for i in lstm_pred_te_pr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be893993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.9705744431418523\n",
      "test accuracy:  0.7542213883677298\n"
     ]
    }
   ],
   "source": [
    "print(\"train accuracy: \", metrics.accuracy_score(y_train, lstm_pred_tr))\n",
    "print(\"test accuracy: \", metrics.accuracy_score(y_test, lstm_pred_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b0e9879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267/267 [==============================] - 2s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(padded_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee3bd959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9916849 ],\n",
       "       [0.9832622 ],\n",
       "       [0.9604677 ],\n",
       "       ...,\n",
       "       [0.33998555],\n",
       "       [0.017466  ],\n",
       "       [0.04674144]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f195126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new array with expanded shape\n",
    "new_pred = np.empty((pred.shape[0], 2), dtype=np.float32)\n",
    "\n",
    "# Copy values to the new array\n",
    "for i in range(pred.shape[0]):\n",
    "    value = pred[i][0]\n",
    "    new_pred[i] = [value, 1 - value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bea137fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9916849 , 0.00831509],\n",
       "       [0.9832622 , 0.01673782],\n",
       "       [0.9604677 , 0.0395323 ],\n",
       "       ...,\n",
       "       [0.33998555, 0.66001445],\n",
       "       [0.017466  , 0.982534  ],\n",
       "       [0.04674144, 0.9532586 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3722e8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29616064], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca020ad",
   "metadata": {},
   "source": [
    "# Text Attack Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63de6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "from textattack.datasets import HuggingFaceDataset\n",
    "from textattack.attack_recipes import TextFoolerJin2019\n",
    "from textattack import Attacker\n",
    "\n",
    "class CustomTensorFlowModelWrapper(ModelWrapper):\n",
    "    def __init__(self, model,total_word):\n",
    "        self.model = model\n",
    "        self.total_word = total_word\n",
    "\n",
    "        \n",
    "    # How this works is TextAttack needs to know how the model preprocesses the text\n",
    "    # Given that, you can then use the model to predict.\n",
    "    def __call__(self, text_input_list):\n",
    "        tokenizer = Tokenizer(num_words = len(self.total_word))\n",
    "        tokenizer.fit_on_texts(text_input_list)\n",
    "        sequences = tokenizer.texts_to_sequences(text_input_list)\n",
    "\n",
    "        # padding\n",
    "        padded = pad_sequences(sequences, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        pred = model.predict(padded)\n",
    "        \n",
    "        # Prediction array must have a positive and negative value for textattack\n",
    "        new_pred = np.empty((pred.shape[0], 2), dtype=np.float32)\n",
    "\n",
    "        for i in range(pred.shape[0]):\n",
    "            value = pred[i][0]\n",
    "            new_pred[i] = [value, 1 - value]\n",
    "    \n",
    "        return new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "667637a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomTensorFlowModelWrapper at 0x220213b6970>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CustomTensorFlowModelWrapper(model=model, total_word=total_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "193eb4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_tensor(attack_recipe,model_wrapper,text_data):\n",
    "    attack = attack_recipe.build(model_wrapper)\n",
    "    \n",
    "    attacker = Attacker(attack,text_data)\n",
    "    attacker.attack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8550db2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (C:/Users/mattl/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60e2be6d1254f648a116c8ede5c3b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mrotten_tomatoes\u001b[0m, split \u001b[94mtrain\u001b[0m.\n"
     ]
    }
   ],
   "source": [
    "model_wrapper = CustomTensorFlowModelWrapper(model,total_word)\n",
    "\n",
    "text_data = HuggingFaceDataset(\"rotten_tomatoes\", None, \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aafb3b6",
   "metadata": {},
   "source": [
    "## TextFoolerJin2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86880f6e",
   "metadata": {},
   "source": [
    "This attack recipe is a word based subsistution attack. It does so by subsituting words with a similar meaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd305cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'keras.engine.sequential.Sequential'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (min_cos_sim):  0.5\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): PartOfSpeech(\n",
      "        (tagger_type):  nltk\n",
      "        (tagset):  universal\n",
      "        (allow_verb_noun_swap):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (2): UniversalSentenceEncoder(\n",
      "        (metric):  angular\n",
      "        (threshold):  0.840845057\n",
      "        (window_size):  15\n",
      "        (skip_text_shorter_than_window):  True\n",
      "        (compare_against_original):  False\n",
      "      )\n",
      "    (3): RepeatModification\n",
      "    (4): StopwordModification\n",
      "    (5): InputColumnModification(\n",
      "        (matching_column_labels):  ['premise', 'hypothesis']\n",
      "        (columns_to_ignore):  {'premise'}\n",
      "      )\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10%|██▉                          | 1/10 [00:00<00:01,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[Negative (74%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████▊                       | 2/10 [00:00<00:00, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Negative (67%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  30%|████████▋                    | 3/10 [00:07<00:17,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 3 ---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  30%|████████▋                    | 3/10 [00:07<00:18,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Positive (52%)]] --> [[Negative (72%)]]\n",
      "\n",
      "[[effective]] but too-tepid biopic\n",
      "\n",
      "[[valid]] but too-tepid biopic\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 3 / 4:  40%|███████████▌                 | 4/10 [00:07<00:11,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[Negative (73%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 4 / 5:  50%|██████████████▌              | 5/10 [00:07<00:07,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 5 / 6:  60%|█████████████████▍           | 6/10 [00:08<00:05,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[Negative (83%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 5 / 7:  70%|████████████████████▎        | 7/10 [00:08<00:03,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "[[Positive (66%)]] --> [[Negative (61%)]]\n",
      "\n",
      "offers that rare combination of entertainment and [[education]] .\n",
      "\n",
      "offers that rare combination of entertainment and [[lectured]] .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 6 / 8:  80%|███████████████████████▏     | 8/10 [00:08<00:02,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 7 / 9:  90%|██████████████████████████   | 9/10 [00:08<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 7 / 10: 100%|███████████████████████████| 10/10 [00:08<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[Positive (51%)]] --> [[Negative (67%)]]\n",
      "\n",
      "take care of my cat offers a [[refreshingly]] different slice of asian cinema .\n",
      "\n",
      "take care of my cat offers a [[brilliantly]] different slice of asian cinema .\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 3      |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 7      |\n",
      "| Original accuracy:            | 30.0%  |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "| Average perturbed word %:     | 15.06% |\n",
      "| Average num. words per input: | 19.5   |\n",
      "| Avg num queries:              | 38.0   |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import TextFoolerJin2019\n",
    "attack_tensor(TextFoolerJin2019,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb94c89",
   "metadata": {},
   "source": [
    "It seems like the pad sequences of the tensorflow model is more robust at fending off this algorithim's attack than the bag of words and tf-idf of the sklearn models (see: Text Attack SKlearn Exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ad0cd",
   "metadata": {},
   "source": [
    "## A2T_yoo_2021 (N/A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d8f9ea",
   "metadata": {},
   "source": [
    "The above attack is meant to be used against BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ecaabb",
   "metadata": {},
   "source": [
    "## Checklist Ribeiro 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd947d",
   "metadata": {},
   "source": [
    "As per the documentation, this attack focuses on a number of attacks used in the Invariance Testing Method: Contraction, Extension, Changing Names, Number, Location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06a92b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'keras.engine.sequential.Sequential'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedySearch\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  CompositeTransformation(\n",
      "    (0): WordSwapExtend\n",
      "    (1): WordSwapContract\n",
      "    (2): WordSwapChangeName\n",
      "    (3): WordSwapChangeNumber\n",
      "    (4): WordSwapChangeLocation\n",
      "    )\n",
      "  (constraints): \n",
      "    (0): RepeatModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10%|██▉                          | 1/10 [00:00<00:00, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[Negative (74%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████▊                       | 2/10 [00:00<00:00, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Negative (67%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2023-11-09 10:59:14,612 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 2 / 3:  30%|████████▋                    | 3/10 [00:03<00:07,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[Positive (52%)]] --> [[[FAILED]]]\n",
      "\n",
      "effective but too-tepid biopic\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 3 / 4:  40%|███████████▌                 | 4/10 [00:03<00:04,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[Negative (73%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 4 / 5:  50%|██████████████▌              | 5/10 [00:03<00:03,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 5 / 6:  60%|█████████████████▍           | 6/10 [00:03<00:02,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[Negative (83%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 5 / 7:  70%|████████████████████▎        | 7/10 [00:03<00:01,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "[[Positive (66%)]] --> [[[FAILED]]]\n",
      "\n",
      "offers that rare combination of entertainment and education .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 6 / 8:  80%|███████████████████████▏     | 8/10 [00:03<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 7 / 9:  90%|██████████████████████████   | 9/10 [00:03<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 7 / 10: 100%|███████████████████████████| 10/10 [00:04<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[Positive (51%)]] --> [[[FAILED]]]\n",
      "\n",
      "take care of my cat offers a refreshingly different slice of asian cinema .\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+-------+\n",
      "| Attack Results                |       |\n",
      "+-------------------------------+-------+\n",
      "| Number of successful attacks: | 0     |\n",
      "| Number of failed attacks:     | 3     |\n",
      "| Number of skipped attacks:    | 7     |\n",
      "| Original accuracy:            | 30.0% |\n",
      "| Accuracy under attack:        | 30.0% |\n",
      "| Attack success rate:          | 0.0%  |\n",
      "| Average perturbed word %:     | nan%  |\n",
      "| Average num. words per input: | 19.5  |\n",
      "| Avg num queries:              | 1.0   |\n",
      "+-------------------------------+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\mattl\\anaconda3\\lib\\site-packages\\textattack\\metrics\\attack_metrics\\words_perturbed.py:83: RuntimeWarning: Mean of empty slice.\n",
      "  average_perc_words_perturbed = self.perturbed_word_percentages.mean()\n",
      "C:\\Users\\mattl\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import CheckList2020\n",
    "attack_tensor(CheckList2020,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577f3204",
   "metadata": {},
   "source": [
    "Compared to Sklearn, again we see that the pad sequences is more robust in defending against such an attack which all the attacks being fialures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d403499",
   "metadata": {},
   "source": [
    "## Clare Li 2020 (Not Working)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c9269a",
   "metadata": {},
   "source": [
    "This algorithim constructs adversarial examples to test the robustness of NLP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9919171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "textattack: Unknown if model of class <class 'keras.engine.sequential.Sequential'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedySearch\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  CompositeTransformation(\n",
      "    (0): WordSwapMaskedLM(\n",
      "        (method):  bae\n",
      "        (masked_lm_name):  RobertaForCausalLM\n",
      "        (max_length):  512\n",
      "        (max_candidates):  50\n",
      "        (min_confidence):  0.0005\n",
      "      )\n",
      "    (1): WordInsertionMaskedLM(\n",
      "        (masked_lm_name):  RobertaForCausalLM\n",
      "        (max_length):  512\n",
      "        (max_candidates):  50\n",
      "        (min_confidence):  0.0\n",
      "      )\n",
      "    (2): WordMergeMaskedLM(\n",
      "        (masked_lm_name):  RobertaForCausalLM\n",
      "        (max_length):  512\n",
      "        (max_candidates):  50\n",
      "        (min_confidence):  0.005\n",
      "      )\n",
      "    )\n",
      "  (constraints): \n",
      "    (0): UniversalSentenceEncoder(\n",
      "        (metric):  cosine\n",
      "        (threshold):  0.7\n",
      "        (window_size):  15\n",
      "        (skip_text_shorter_than_window):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10%|██▉                          | 1/10 [00:00<00:00, 19.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[Negative (74%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████▊                       | 2/10 [00:00<00:00, 20.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Negative (67%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'upos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextattack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattack_recipes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CLARE2020\n\u001b[1;32m----> 2\u001b[0m \u001b[43mattack_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCLARE2020\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtext_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m, in \u001b[0;36mattack_tensor\u001b[1;34m(attack_recipe, model_wrapper, text_data)\u001b[0m\n\u001b[0;32m      2\u001b[0m attack \u001b[38;5;241m=\u001b[39m attack_recipe\u001b[38;5;241m.\u001b[39mbuild(model_wrapper)\n\u001b[0;32m      4\u001b[0m attacker \u001b[38;5;241m=\u001b[39m Attacker(attack,text_data)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mattacker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:441\u001b[0m, in \u001b[0;36mAttacker.attack_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attack_parallel()\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39msilent:\n\u001b[0;32m    444\u001b[0m     logger\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mINFO)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:170\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack\u001b[38;5;241m.\u001b[39mattack(example, ground_truth_output)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, SkippedAttackResult) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mattack_n\n\u001b[0;32m    173\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, SuccessfulAttackResult)\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mnum_successful_examples\n\u001b[0;32m    176\u001b[0m ):\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m worklist_candidates:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:168\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m     example\u001b[38;5;241m.\u001b[39mattack_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mlabel_names\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:450\u001b[0m, in \u001b[0;36mAttack.attack\u001b[1;34m(self, example, ground_truth_output)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SkippedAttackResult(goal_function_result)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 450\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoal_function_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:398\u001b[0m, in \u001b[0;36mAttack._attack\u001b[1;34m(self, initial_result)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_attack\u001b[39m(\u001b[38;5;28mself\u001b[39m, initial_result):\n\u001b[0;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the ``SearchMethod`` to perturb the ``AttackedText`` stored in\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m    ``initial_result``.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m            or ``MaximizedAttackResult``.\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     final_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_cache()\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_result\u001b[38;5;241m.\u001b[39mgoal_status \u001b[38;5;241m==\u001b[39m GoalFunctionResultStatus\u001b[38;5;241m.\u001b[39mSUCCEEDED:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\search_methods\\search_method.py:36\u001b[0m, in \u001b[0;36mSearchMethod.__call__\u001b[1;34m(self, initial_result)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter_transformations\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch Method must have access to filter_transformations method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m     )\n\u001b[1;32m---> 36\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# ensure that the number of queries for this GoalFunctionResult is up-to-date\u001b[39;00m\n\u001b[0;32m     38\u001b[0m result\u001b[38;5;241m.\u001b[39mnum_queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoal_function\u001b[38;5;241m.\u001b[39mnum_queries\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\search_methods\\beam_search.py:32\u001b[0m, in \u001b[0;36mBeamSearch.perform_search\u001b[1;34m(self, initial_result)\u001b[0m\n\u001b[0;32m     30\u001b[0m potential_next_beam \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m beam:\n\u001b[1;32m---> 32\u001b[0m     transformations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattacked_text\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     potential_next_beam \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m transformations\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(potential_next_beam) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# If we did not find any possible perturbations, give up.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:305\u001b[0m, in \u001b[0;36mAttack.get_transformations\u001b[1;34m(self, current_text, original_text, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m     transformed_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_cache[cache_key])\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 305\u001b[0m     transformed_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_transformations_uncached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mhashable(cache_key):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_cache[cache_key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(transformed_texts)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:273\u001b[0m, in \u001b[0;36mAttack._get_transformations_uncached\u001b[1;34m(self, current_text, original_text, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_transformations_uncached\u001b[39m(\u001b[38;5;28mself\u001b[39m, current_text, original_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    264\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies ``self.transformation`` to ``text``, then filters the list\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    of possible transformations through the applicable constraints.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m        A filtered list of transformations where each transformation matches the constraints\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     transformed_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpre_transformation_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_transformation_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformed_texts\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\transformations\\composite_transformation.py:39\u001b[0m, in \u001b[0;36mCompositeTransformation.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m new_attacked_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transformation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformations:\n\u001b[1;32m---> 39\u001b[0m     new_attacked_texts\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mtransformation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(new_attacked_texts)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\transformations\\transformation.py:57\u001b[0m, in \u001b[0;36mTransformation.__call__\u001b[1;34m(self, current_text, pre_transformation_constraints, indices_to_modify, shifted_idxs, return_indices)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_indices:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indices_to_modify\n\u001b[1;32m---> 57\u001b[0m transformed_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_transformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_to_modify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m transformed_texts:\n\u001b[0;32m     59\u001b[0m     text\u001b[38;5;241m.\u001b[39mattack_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_transformation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\transformations\\word_merges\\word_merge_masked_lm.py:162\u001b[0m, in \u001b[0;36mWordMergeMaskedLM._get_transformations\u001b[1;34m(self, current_text, indices_to_modify)\u001b[0m\n\u001b[0;32m    160\u001b[0m indices_to_modify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(indices_to_modify)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# find indices that are suitable to merge\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m token_tags \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    163\u001b[0m     current_text\u001b[38;5;241m.\u001b[39mpos_of_word_index(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(current_text\u001b[38;5;241m.\u001b[39mnum_words)\n\u001b[0;32m    164\u001b[0m ]\n\u001b[0;32m    165\u001b[0m merge_indices \u001b[38;5;241m=\u001b[39m find_merge_index(token_tags)\n\u001b[0;32m    166\u001b[0m merged_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merged_words(current_text, merge_indices)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\transformations\\word_merges\\word_merge_masked_lm.py:163\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    160\u001b[0m indices_to_modify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(indices_to_modify)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# find indices that are suitable to merge\u001b[39;00m\n\u001b[0;32m    162\u001b[0m token_tags \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 163\u001b[0m     \u001b[43mcurrent_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_of_word_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(current_text\u001b[38;5;241m.\u001b[39mnum_words)\n\u001b[0;32m    164\u001b[0m ]\n\u001b[0;32m    165\u001b[0m merge_indices \u001b[38;5;241m=\u001b[39m find_merge_index(token_tags)\n\u001b[0;32m    166\u001b[0m merged_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merged_words(current_text, merge_indices)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\shared\\attacked_text.py:141\u001b[0m, in \u001b[0;36mAttackedText.pos_of_word_index\u001b[1;34m(self, desired_word_idx)\u001b[0m\n\u001b[0;32m    139\u001b[0m     textattack\u001b[38;5;241m.\u001b[39mshared\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mflair_tag(sentence)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos_tags \u001b[38;5;241m=\u001b[39m sentence\n\u001b[1;32m--> 141\u001b[0m flair_word_list, flair_pos_list \u001b[38;5;241m=\u001b[39m \u001b[43mtextattack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzip_flair_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pos_tags\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word_idx, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwords):\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    147\u001b[0m         word \u001b[38;5;129;01min\u001b[39;00m flair_word_list\n\u001b[0;32m    148\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword absent in flair returned part-of-speech tags\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\shared\\utils\\strings.py:245\u001b[0m, in \u001b[0;36mzip_flair_result\u001b[1;34m(pred, tag_type)\u001b[0m\n\u001b[0;32m    243\u001b[0m word_list\u001b[38;5;241m.\u001b[39mappend(token\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tag_type:\n\u001b[1;32m--> 245\u001b[0m     pos_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mannotation_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_value)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tag_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    247\u001b[0m     pos_list\u001b[38;5;241m.\u001b[39mappend(token\u001b[38;5;241m.\u001b[39mget_label(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'upos'"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import CLARE2020\n",
    "attack_tensor(CLARE2020,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0b6fc",
   "metadata": {},
   "source": [
    "## Faster Alzantot Genetic Algorithm (Not Working) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b7bc43",
   "metadata": {},
   "source": [
    "This Algorithm implements an optimization algorithm inspired by the proccess of natural selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a997188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattl\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.01 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "textattack: Unknown if model of class <class 'keras.engine.sequential.Sequential'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): AlzantotGeneticAlgorithm(\n",
      "    (pop_size):  60\n",
      "    (max_iters):  40\n",
      "    (temp):  0.3\n",
      "    (give_up_if_no_improvement):  False\n",
      "    (post_crossover_check):  False\n",
      "    (max_crossover_retries):  20\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  8\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): MaxWordsPerturbed(\n",
      "        (max_percent):  0.2\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (max_mse_dist):  0.5\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (2): LearningToWriteLanguageModel(\n",
      "        (max_log_prob_diff):  5.0\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (3): RepeatModification\n",
      "    (4): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10%|██▉                          | 1/10 [00:00<00:00, 14.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[Negative (74%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  20%|█████▊                       | 2/10 [00:00<00:00, 15.50it/s]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████▊                       | 2/10 [00:00<00:00, 15.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Negative (67%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index is out of bounds for dimension with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\constraints\\grammaticality\\language_models\\learning_to_write\\language_model_helpers.py:35\u001b[0m, in \u001b[0;36mQueryHandler.query\u001b[1;34m(self, sentences, swapped_words, batch_size)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswapped_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\constraints\\grammaticality\\language_models\\learning_to_write\\language_model_helpers.py:76\u001b[0m, in \u001b[0;36mQueryHandler.try_query\u001b[1;34m(self, sentences, swapped_words, batch_size)\u001b[0m\n\u001b[0;32m     73\u001b[0m all_raw_idxs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m     74\u001b[0m     raw_idx_list, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong\n\u001b[0;32m     75\u001b[0m )\n\u001b[1;32m---> 76\u001b[0m word_idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapto\u001b[49m\u001b[43m[\u001b[49m\u001b[43mall_raw_idxs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     77\u001b[0m hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39minit_hidden(\u001b[38;5;28mlen\u001b[39m(batch))\n",
      "\u001b[1;31mIndexError\u001b[0m: index is out of bounds for dimension with size 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextattack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattack_recipes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FasterGeneticAlgorithmJia2019\n\u001b[1;32m----> 2\u001b[0m \u001b[43mattack_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFasterGeneticAlgorithmJia2019\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtext_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m, in \u001b[0;36mattack_tensor\u001b[1;34m(attack_recipe, model_wrapper, text_data)\u001b[0m\n\u001b[0;32m      2\u001b[0m attack \u001b[38;5;241m=\u001b[39m attack_recipe\u001b[38;5;241m.\u001b[39mbuild(model_wrapper)\n\u001b[0;32m      4\u001b[0m attacker \u001b[38;5;241m=\u001b[39m Attacker(attack,text_data)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mattacker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:441\u001b[0m, in \u001b[0;36mAttacker.attack_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attack_parallel()\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39msilent:\n\u001b[0;32m    444\u001b[0m     logger\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mINFO)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:170\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack\u001b[38;5;241m.\u001b[39mattack(example, ground_truth_output)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, SkippedAttackResult) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mattack_n\n\u001b[0;32m    173\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, SuccessfulAttackResult)\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mnum_successful_examples\n\u001b[0;32m    176\u001b[0m ):\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m worklist_candidates:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:168\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m     example\u001b[38;5;241m.\u001b[39mattack_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mlabel_names\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:450\u001b[0m, in \u001b[0;36mAttack.attack\u001b[1;34m(self, example, ground_truth_output)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SkippedAttackResult(goal_function_result)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 450\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoal_function_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:398\u001b[0m, in \u001b[0;36mAttack._attack\u001b[1;34m(self, initial_result)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_attack\u001b[39m(\u001b[38;5;28mself\u001b[39m, initial_result):\n\u001b[0;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the ``SearchMethod`` to perturb the ``AttackedText`` stored in\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m    ``initial_result``.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m            or ``MaximizedAttackResult``.\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     final_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_cache()\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_result\u001b[38;5;241m.\u001b[39mgoal_status \u001b[38;5;241m==\u001b[39m GoalFunctionResultStatus\u001b[38;5;241m.\u001b[39mSUCCEEDED:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\search_methods\\search_method.py:36\u001b[0m, in \u001b[0;36mSearchMethod.__call__\u001b[1;34m(self, initial_result)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter_transformations\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch Method must have access to filter_transformations method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m     )\n\u001b[1;32m---> 36\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# ensure that the number of queries for this GoalFunctionResult is up-to-date\u001b[39;00m\n\u001b[0;32m     38\u001b[0m result\u001b[38;5;241m.\u001b[39mnum_queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoal_function\u001b[38;5;241m.\u001b[39mnum_queries\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\search_methods\\genetic_algorithm.py:236\u001b[0m, in \u001b[0;36mGeneticAlgorithm.perform_search\u001b[1;34m(self, initial_result)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, initial_result):\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_over \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     population \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m     pop_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(population)\n\u001b[0;32m    238\u001b[0m     current_score \u001b[38;5;241m=\u001b[39m initial_result\u001b[38;5;241m.\u001b[39mscore\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\search_methods\\alzantot_genetic_algorithm.py:110\u001b[0m, in \u001b[0;36mAlzantotGeneticAlgorithm._initialize_population\u001b[1;34m(self, initial_result, pop_size)\u001b[0m\n\u001b[0;32m    108\u001b[0m words \u001b[38;5;241m=\u001b[39m initial_result\u001b[38;5;241m.\u001b[39mattacked_text\u001b[38;5;241m.\u001b[39mwords\n\u001b[0;32m    109\u001b[0m num_candidate_transformations \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(words))\n\u001b[1;32m--> 110\u001b[0m transformed_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattacked_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattacked_text\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transformed_text \u001b[38;5;129;01min\u001b[39;00m transformed_texts:\n\u001b[0;32m    114\u001b[0m     diff_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;28miter\u001b[39m(transformed_text\u001b[38;5;241m.\u001b[39mattack_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewly_modified_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    116\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:315\u001b[0m, in \u001b[0;36mAttack.get_transformations\u001b[1;34m(self, current_text, original_text, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    311\u001b[0m     transformed_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_transformations_uncached(\n\u001b[0;32m    312\u001b[0m         current_text, original_text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    313\u001b[0m     )\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformed_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_text\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:380\u001b[0m, in \u001b[0;36mAttack.filter_transformations\u001b[1;34m(self, transformed_texts, current_text, original_text)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraints_cache[(current_text, transformed_text)]:\n\u001b[0;32m    379\u001b[0m             filtered_texts\u001b[38;5;241m.\u001b[39mappend(transformed_text)\n\u001b[1;32m--> 380\u001b[0m filtered_texts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_transformations_uncached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43muncached_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moriginal_text\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# Sort transformations to ensure order is preserved between runs\u001b[39;00m\n\u001b[0;32m    384\u001b[0m filtered_texts\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: t\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:340\u001b[0m, in \u001b[0;36mAttack._filter_transformations_uncached\u001b[1;34m(self, transformed_texts, current_text, original_text)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m original_text:\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing `original_text` argument when constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(C)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is set to compare against `original_text`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m         )\n\u001b[1;32m--> 340\u001b[0m     filtered_texts \u001b[38;5;241m=\u001b[39m \u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_many\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    342\u001b[0m     filtered_texts \u001b[38;5;241m=\u001b[39m C\u001b[38;5;241m.\u001b[39mcall_many(filtered_texts, current_text)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\constraints\\constraint.py:50\u001b[0m, in \u001b[0;36mConstraint.call_many\u001b[1;34m(self, transformed_texts, reference_text)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m     48\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformed_text must have `last_transformation` attack_attr to apply constraint\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     49\u001b[0m         )\n\u001b[1;32m---> 50\u001b[0m filtered_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_constraint_many\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompatible_transformed_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_text\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(filtered_texts) \u001b[38;5;241m+\u001b[39m incompatible_transformed_texts\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\constraints\\constraint.py:63\u001b[0m, in \u001b[0;36mConstraint._check_constraint_many\u001b[1;34m(self, transformed_texts, reference_text)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_constraint_many\u001b[39m(\u001b[38;5;28mself\u001b[39m, transformed_texts, reference_text):\n\u001b[0;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Filters ``transformed_texts`` based on which transformations fulfill\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    the constraint. Calls ``check_constraint``\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m        reference_texts (AttackedText): The ``AttackedText`` to compare against.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     64\u001b[0m         transformed_text\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m transformed_text \u001b[38;5;129;01min\u001b[39;00m transformed_texts\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_constraint(transformed_text, reference_text)\n\u001b[0;32m     67\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\constraints\\constraint.py:66\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_constraint_many\u001b[39m(\u001b[38;5;28mself\u001b[39m, transformed_texts, reference_text):\n\u001b[0;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Filters ``transformed_texts`` based on which transformations fulfill\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    the constraint. Calls ``check_constraint``\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m        reference_texts (AttackedText): The ``AttackedText`` to compare against.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     64\u001b[0m         transformed_text\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m transformed_text \u001b[38;5;129;01min\u001b[39;00m transformed_texts\n\u001b[1;32m---> 66\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_constraint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\constraints\\grammaticality\\language_models\\language_model_constraint.py:44\u001b[0m, in \u001b[0;36mLanguageModelConstraint._check_constraint\u001b[1;34m(self, transformed_text, reference_text)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot apply language model constraint without `newly_modified_indices`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m     )\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[1;32m---> 44\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_log_probs_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreference_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_text\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(probs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     47\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: get_log_probs_at_index returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(probs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m values for 2 inputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\constraints\\grammaticality\\language_models\\learning_to_write\\learning_to_write.py:60\u001b[0m, in \u001b[0;36mLearningToWriteLanguageModel.get_log_probs_at_index\u001b[1;34m(self, text_list, word_index)\u001b[0m\n\u001b[0;32m     58\u001b[0m     queries\u001b[38;5;241m.\u001b[39mappend(query)\n\u001b[0;32m     59\u001b[0m     query_words\u001b[38;5;241m.\u001b[39mappend(word)\n\u001b[1;32m---> 60\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_words\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(log_probs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\constraints\\grammaticality\\language_models\\learning_to_write\\language_model_helpers.py:40\u001b[0m, in \u001b[0;36mQueryHandler.query\u001b[1;34m(self, sentences, swapped_words, batch_size)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s, w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sentences, swapped_words):\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m         probs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtry_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mw\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     43\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING:  got runtime error trying languag emodel on language model w s/w\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m             s,\n\u001b[0;32m     45\u001b[0m             w,\n\u001b[0;32m     46\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\constraints\\grammaticality\\language_models\\learning_to_write\\language_model_helpers.py:76\u001b[0m, in \u001b[0;36mQueryHandler.try_query\u001b[1;34m(self, sentences, swapped_words, batch_size)\u001b[0m\n\u001b[0;32m     72\u001b[0m num_idxs_dropped \u001b[38;5;241m=\u001b[39m orig_num_idxs \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(raw_idx_list)\n\u001b[0;32m     73\u001b[0m all_raw_idxs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[0;32m     74\u001b[0m     raw_idx_list, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong\n\u001b[0;32m     75\u001b[0m )\n\u001b[1;32m---> 76\u001b[0m word_idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapto\u001b[49m\u001b[43m[\u001b[49m\u001b[43mall_raw_idxs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     77\u001b[0m hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39minit_hidden(\u001b[38;5;28mlen\u001b[39m(batch))\n\u001b[0;32m     78\u001b[0m source \u001b[38;5;241m=\u001b[39m word_idxs[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "\u001b[1;31mIndexError\u001b[0m: index is out of bounds for dimension with size 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████▊                       | 2/10 [00:14<00:58,  7.36s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import FasterGeneticAlgorithmJia2019\n",
    "attack_tensor(FasterGeneticAlgorithmJia2019,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69bd3e",
   "metadata": {},
   "source": [
    "## Hotflip (hotflip_ebrahimi_2017) - Not Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0adbb70b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CustomTensorFlowModelWrapper' object has no attribute 'tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextattack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattack_recipes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HotFlipEbrahimi2017\n\u001b[1;32m----> 2\u001b[0m \u001b[43mattack_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHotFlipEbrahimi2017\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtext_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m, in \u001b[0;36mattack_tensor\u001b[1;34m(attack_recipe, model_wrapper, text_data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattack_tensor\u001b[39m(attack_recipe,model_wrapper,text_data):\n\u001b[1;32m----> 2\u001b[0m     attack \u001b[38;5;241m=\u001b[39m \u001b[43mattack_recipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_wrapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     attacker \u001b[38;5;241m=\u001b[39m Attacker(attack,text_data)\n\u001b[0;32m      5\u001b[0m     attacker\u001b[38;5;241m.\u001b[39mattack_dataset()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack_recipes\\hotflip_ebrahimi_2017.py:40\u001b[0m, in \u001b[0;36mHotFlipEbrahimi2017.build\u001b[1;34m(model_wrapper)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(model_wrapper):\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# \"HotFlip ... uses the gradient with respect to a one-hot input\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# representation to efficiently estimate which individual change has the\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# highest estimated loss.\"\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     transformation \u001b[38;5;241m=\u001b[39m \u001b[43mWordSwapGradientBased\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# Don't modify the same word twice or stopwords\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     constraints \u001b[38;5;241m=\u001b[39m [RepeatModification(), StopwordModification()]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\transformations\\word_swaps\\word_swap_gradient_based.py:41\u001b[0m, in \u001b[0;36mWordSwapGradientBased.__init__\u001b[1;34m(self, model_wrapper, top_n)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model_wrapper\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapper \u001b[38;5;241m=\u001b[39m model_wrapper\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Make sure we know how to compute the gradient for this model.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m validate_model_gradient_word_swap_compatibility(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CustomTensorFlowModelWrapper' object has no attribute 'tokenizer'"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import HotFlipEbrahimi2017\n",
    "attack_tensor(HotFlipEbrahimi2017,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978fc977",
   "metadata": {},
   "source": [
    "## Improved Genetic Algorithm (Iga Wang 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b19305c",
   "metadata": {},
   "source": [
    "This is an improved genetic algorithim. It also poisons the input to cause training accuracy deficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4c5f57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'keras.engine.sequential.Sequential'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): ImprovedGeneticAlgorithm(\n",
      "    (pop_size):  60\n",
      "    (max_iters):  20\n",
      "    (temp):  0.3\n",
      "    (give_up_if_no_improvement):  False\n",
      "    (post_crossover_check):  False\n",
      "    (max_crossover_retries):  20\n",
      "    (max_replace_times_per_index):  5\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): MaxWordsPerturbed(\n",
      "        (max_percent):  0.2\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (max_mse_dist):  0.5\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  False\n",
      "      )\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10%|██▉                          | 1/10 [00:00<00:00, 16.95it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[Negative (74%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  20%|█████▊                       | 2/10 [00:00<00:00, 16.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████▊                       | 2/10 [00:00<00:00, 16.26it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Negative (67%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[Positive (52%)]] --> [[Negative (53%)]]\n",
      "\n",
      "[[effective]] but too-tepid biopic\n",
      "\n",
      "[[effectively]] but too-tepid biopic"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  30%|████████▋                    | 3/10 [00:00<00:00,  9.35it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  40%|███████████▌                 | 4/10 [00:00<00:00, 10.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 3 / 4:  40%|███████████▌                 | 4/10 [00:00<00:00, 10.53it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[Negative (73%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 4 / 5:  50%|██████████████▌              | 5/10 [00:00<00:00, 11.47it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 4 / 5:  60%|█████████████████▍           | 6/10 [00:00<00:00, 12.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 5 / 6:  60%|█████████████████▍           | 6/10 [00:00<00:00, 12.20it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[Negative (83%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 5 / 7:  70%|████████████████████▎        | 7/10 [00:00<00:00,  8.46it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "[[Positive (66%)]] --> [[Negative (66%)]]\n",
      "\n",
      "offers that rare [[combination]] of entertainment and education .\n",
      "\n",
      "offers that rare [[jumpsuit]] of entertainment and education .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 5 / 7:  80%|███████████████████████▏     | 8/10 [00:00<00:00,  8.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 6 / 8:  80%|███████████████████████▏     | 8/10 [00:00<00:00,  8.88it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 7 / 9:  90%|██████████████████████████   | 9/10 [00:00<00:00,  9.39it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 7 / 9: 100%|████████████████████████████| 10/10 [00:01<00:00,  6.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 7 / 10: 100%|███████████████████████████| 10/10 [00:01<00:00,  6.30it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[Positive (51%)]] --> [[Negative (70%)]]\n",
      "\n",
      "take care of my cat [[offers]] a refreshingly different slice of asian cinema .\n",
      "\n",
      "take care of my cat [[offering]] a refreshingly different slice of asian cinema .\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 3      |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 7      |\n",
      "| Original accuracy:            | 30.0%  |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "| Average perturbed word %:     | 15.06% |\n",
      "| Average num. words per input: | 19.5   |\n",
      "| Avg num queries:              | 52.67  |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import IGAWang2019\n",
    "attack_tensor(IGAWang2019,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d4cc4d",
   "metadata": {},
   "source": [
    "## Input Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40da982",
   "metadata": {},
   "source": [
    "This attack removes words in the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12f203e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'keras.engine.sequential.Sequential'> compatible with goal function <class 'textattack.goal_functions.classification.input_reduction.InputReduction'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  InputReduction(\n",
      "    (maximizable):  True\n",
      "  )\n",
      "  (transformation):  WordDeletion\n",
      "  (constraints): \n",
      "    (0): RepeatModification\n",
      "    (1): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10%|██▉                          | 1/10 [00:00<00:00, 15.15it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[Negative (74%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  20%|█████▊                       | 2/10 [00:00<00:00, 16.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████▊                       | 2/10 [00:00<00:00, 15.87it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Negative (67%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  30%|████████▋                    | 3/10 [00:00<00:00,  8.55it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[Positive (52%)]] --> [[Positive (67%)]]\n",
      "\n",
      "[[effective]] but [[too-tepid]] biopic\n",
      "\n",
      "but biopic\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  40%|███████████▌                 | 4/10 [00:00<00:00,  9.71it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[Negative (73%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 3 / 4:  40%|███████████▌                 | 4/10 [00:00<00:00,  9.61it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 4 / 5:  50%|██████████████▌              | 5/10 [00:00<00:00, 10.31it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 4 / 5:  60%|█████████████████▍           | 6/10 [00:00<00:00, 11.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 5 / 6:  60%|█████████████████▍           | 6/10 [00:00<00:00, 10.95it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[Negative (83%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 5 / 7:  70%|████████████████████▎        | 7/10 [00:01<00:00,  6.67it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Positive (66%)]] --> [[Positive (63%)]]\n",
      "\n",
      "offers that rare combination of [[entertainment]] and education .\n",
      "\n",
      "offers that rare combination of and education .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 5 / 7:  80%|███████████████████████▏     | 8/10 [00:01<00:00,  7.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 6 / 8:  80%|███████████████████████▏     | 8/10 [00:01<00:00,  7.17it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 7 / 9:  90%|██████████████████████████   | 9/10 [00:01<00:00,  7.65it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 7 / 9: 100%|████████████████████████████| 10/10 [00:01<00:00,  5.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 7 / 10: 100%|███████████████████████████| 10/10 [00:01<00:00,  5.55it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[Positive (51%)]] --> [[Positive (66%)]]\n",
      "\n",
      "take care [[of]] my [[cat]] [[offers]] a [[refreshingly]] different slice of [[asian]] cinema .\n",
      "\n",
      "take care my a different slice of cinema .\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 3      |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 7      |\n",
      "| Original accuracy:            | 30.0%  |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "| Average perturbed word %:     | 40.38% |\n",
      "| Average num. words per input: | 19.5   |\n",
      "| Avg num queries:              | 15.33  |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import InputReductionFeng2018\n",
    "attack_tensor(InputReductionFeng2018,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc0b04",
   "metadata": {},
   "source": [
    "## Kuleshov 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29169a8",
   "metadata": {},
   "source": [
    "This is an algorithim designed to generate adversial examples to poison the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98dafe09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'keras.engine.sequential.Sequential'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedySearch\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  15\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): MaxWordsPerturbed(\n",
      "        (max_percent):  0.5\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): ThoughtVector(\n",
      "        (word_embedding):  WordEmbedding\n",
      "        (metric):  max_euclidean\n",
      "        (threshold):  -0.2\n",
      "        (window_size):  inf\n",
      "        (skip_text_shorter_than_window):  False\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (2): GPT2(\n",
      "        (max_log_prob_diff):  2.0\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (3): RepeatModification\n",
      "    (4): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10%|██▉                          | 1/10 [00:00<00:00, 16.67it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[Negative (74%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  20%|█████▊                       | 2/10 [00:00<00:00, 17.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████▊                       | 2/10 [00:00<00:00, 16.67it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Negative (67%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 3 / 3:  30%|████████▋                    | 3/10 [00:00<00:00, 16.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[Positive (52%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "effective but too-tepid biopic\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 3 / 3:  40%|███████████▌                 | 4/10 [00:00<00:00, 17.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 4 / 4:  40%|███████████▌                 | 4/10 [00:00<00:00, 16.88it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[Negative (73%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 5 / 5:  50%|██████████████▌              | 5/10 [00:00<00:00, 16.89it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 5 / 5:  60%|█████████████████▍           | 6/10 [00:00<00:00, 16.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 6 / 6:  60%|█████████████████▍           | 6/10 [00:00<00:00, 16.57it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[Negative (83%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 7 / 7:  70%|████████████████████▎        | 7/10 [00:00<00:00, 16.55it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "[[Positive (66%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "offers that rare combination of entertainment and education .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 7 / 7:  80%|███████████████████████▏     | 8/10 [00:00<00:00, 16.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 8 / 8:  80%|███████████████████████▏     | 8/10 [00:00<00:00, 16.56it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 9 / 9:  90%|██████████████████████████   | 9/10 [00:00<00:00, 16.67it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 9 / 9: 100%|████████████████████████████| 10/10 [00:00<00:00, 16.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 10 / 10: 100%|██████████████████████████| 10/10 [00:00<00:00, 16.64it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[Positive (51%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "take care of my cat offers a refreshingly different slice of asian cinema .\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+------+\n",
      "| Attack Results                |      |\n",
      "+-------------------------------+------+\n",
      "| Number of successful attacks: | 0    |\n",
      "| Number of failed attacks:     | 0    |\n",
      "| Number of skipped attacks:    | 10   |\n",
      "| Original accuracy:            | 0.0% |\n",
      "| Accuracy under attack:        | 0.0% |\n",
      "| Attack success rate:          | 0%   |\n",
      "| Average perturbed word %:     | nan% |\n",
      "| Average num. words per input: | 19.5 |\n",
      "| Avg num queries:              | nan  |\n",
      "+-------------------------------+------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\mattl\\anaconda3\\lib\\site-packages\\textattack\\metrics\\attack_metrics\\attack_queries.py:39: RuntimeWarning: Mean of empty slice.\n",
      "  avg_num_queries = self.num_queries.mean()\n"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import Kuleshov2017\n",
    "attack_tensor(Kuleshov2017,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69313f00",
   "metadata": {},
   "source": [
    "The attacks appear to not work for this model or rather all of them were skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e54a57",
   "metadata": {},
   "source": [
    "## Morpheus Tan 2020 (doesn't work)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1fe94",
   "metadata": {},
   "source": [
    "Seems to be for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be56a8c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'keras.engine.sequential.Sequential'> compatible with goal function <class 'textattack.goal_functions.text.minimize_bleu.MinimizeBleu'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedySearch\n",
      "  (goal_function):  MinimizeBleu(\n",
      "    (maximizable):  False\n",
      "    (target_bleu):  0.0\n",
      "  )\n",
      "  (transformation):  WordSwapInflections\n",
      "  (constraints): \n",
      "    (0): RepeatModification\n",
      "    (1): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid text_input type <class 'torch.Tensor'> (required str or OrderedDict)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextattack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattack_recipes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MorpheusTan2020\n\u001b[1;32m----> 2\u001b[0m \u001b[43mattack_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMorpheusTan2020\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtext_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m, in \u001b[0;36mattack_tensor\u001b[1;34m(attack_recipe, model_wrapper, text_data)\u001b[0m\n\u001b[0;32m      2\u001b[0m attack \u001b[38;5;241m=\u001b[39m attack_recipe\u001b[38;5;241m.\u001b[39mbuild(model_wrapper)\n\u001b[0;32m      4\u001b[0m attacker \u001b[38;5;241m=\u001b[39m Attacker(attack,text_data)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mattacker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:441\u001b[0m, in \u001b[0;36mAttacker.attack_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attack_parallel()\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39msilent:\n\u001b[0;32m    444\u001b[0m     logger\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mINFO)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:170\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack\u001b[38;5;241m.\u001b[39mattack(example, ground_truth_output)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, SkippedAttackResult) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mattack_n\n\u001b[0;32m    173\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, SuccessfulAttackResult)\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mnum_successful_examples\n\u001b[0;32m    176\u001b[0m ):\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m worklist_candidates:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:168\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m     example\u001b[38;5;241m.\u001b[39mattack_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mlabel_names\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:444\u001b[0m, in \u001b[0;36mAttack.attack\u001b[1;34m(self, example, ground_truth_output)\u001b[0m\n\u001b[0;32m    439\u001b[0m     example \u001b[38;5;241m=\u001b[39m AttackedText(example)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    442\u001b[0m     ground_truth_output, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    443\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`ground_truth_output` must either be `str` or `int`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 444\u001b[0m goal_function_result, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoal_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_attack_example\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_output\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m goal_function_result\u001b[38;5;241m.\u001b[39mgoal_status \u001b[38;5;241m==\u001b[39m GoalFunctionResultStatus\u001b[38;5;241m.\u001b[39mSKIPPED:\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SkippedAttackResult(goal_function_result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:68\u001b[0m, in \u001b[0;36mGoalFunction.init_attack_example\u001b[1;34m(self, attacked_text, ground_truth_output)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mground_truth_output \u001b[38;5;241m=\u001b[39m ground_truth_output\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 68\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattacked_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_skip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, _\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:79\u001b[0m, in \u001b[0;36mGoalFunction.get_result\u001b[1;34m(self, attacked_text, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, attacked_text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A helper method that queries ``self.get_results`` with a single\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    ``AttackedText`` object.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     results, search_over \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mattacked_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     result \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, search_over\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:99\u001b[0m, in \u001b[0;36mGoalFunction.get_results\u001b[1;34m(self, attacked_text_list, check_skip)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attacked_text, raw_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(attacked_text_list, model_outputs):\n\u001b[0;32m     98\u001b[0m     displayed_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_displayed_output(raw_output)\n\u001b[1;32m---> 99\u001b[0m     goal_status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_goal_status\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattacked_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_skip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_skip\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     goal_function_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_score(raw_output, attacked_text)\n\u001b[0;32m    103\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_goal_function_result_type()(\n\u001b[0;32m    105\u001b[0m             attacked_text,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m         )\n\u001b[0;32m    113\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:117\u001b[0m, in \u001b[0;36mGoalFunction._get_goal_status\u001b[1;34m(self, model_output, attacked_text, check_skip)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_goal_status\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_output, attacked_text, check_skip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 117\u001b[0m     should_skip \u001b[38;5;241m=\u001b[39m check_skip \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_skip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattacked_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_skip:\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m GoalFunctionResultStatus\u001b[38;5;241m.\u001b[39mSKIPPED\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:131\u001b[0m, in \u001b[0;36mGoalFunction._should_skip\u001b[1;34m(self, model_output, attacked_text)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_should_skip\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_output, attacked_text):\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_goal_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattacked_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\text\\minimize_bleu.py:46\u001b[0m, in \u001b[0;36mMinimizeBleu._is_goal_complete\u001b[1;34m(self, model_output, _)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_goal_complete\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_output, _):\n\u001b[1;32m---> 46\u001b[0m     bleu_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bleu_score \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_bleu \u001b[38;5;241m+\u001b[39m MinimizeBleu\u001b[38;5;241m.\u001b[39mEPS)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\text\\minimize_bleu.py:50\u001b[0m, in \u001b[0;36mMinimizeBleu._get_score\u001b[1;34m(self, model_output, _)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_score\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_output, _):\n\u001b[1;32m---> 50\u001b[0m     model_output_at \u001b[38;5;241m=\u001b[39m \u001b[43mtextattack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAttackedText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     ground_truth_at \u001b[38;5;241m=\u001b[39m textattack\u001b[38;5;241m.\u001b[39mshared\u001b[38;5;241m.\u001b[39mAttackedText(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mground_truth_output)\n\u001b[0;32m     52\u001b[0m     bleu_score \u001b[38;5;241m=\u001b[39m get_bleu(model_output_at, ground_truth_at)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\shared\\attacked_text.py:55\u001b[0m, in \u001b[0;36mAttackedText.__init__\u001b[1;34m(self, text_input, attack_attrs)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_input \u001b[38;5;241m=\u001b[39m text_input\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid text_input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(text_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (required str or OrderedDict)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m     )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Process input lazily.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid text_input type <class 'torch.Tensor'> (required str or OrderedDict)"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import MorpheusTan2020\n",
    "attack_tensor(MorpheusTan2020,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c95f502",
   "metadata": {},
   "source": [
    "## Pruthi 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d56cb",
   "metadata": {},
   "source": [
    "This is an algorithim that swaps characters either by inserting or deleting them. It targets characters that are on adjacent keys on a QWERTY keyboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "514e4f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'keras.engine.sequential.Sequential'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedySearch\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  CompositeTransformation(\n",
      "    (0): WordSwapNeighboringCharacterSwap(\n",
      "        (random_one):  False\n",
      "      )\n",
      "    (1): WordSwapRandomCharacterDeletion(\n",
      "        (random_one):  False\n",
      "      )\n",
      "    (2): WordSwapRandomCharacterInsertion(\n",
      "        (random_one):  False\n",
      "      )\n",
      "    (3): WordSwapQWERTY\n",
      "    )\n",
      "  (constraints): \n",
      "    (0): MaxWordsPerturbed(\n",
      "        (max_num_words):  1\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): MinWordLength\n",
      "    (2): StopwordModification\n",
      "    (3): RepeatModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10%|██▉                          | 1/10 [00:00<00:00, 15.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[Negative (74%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  20%|█████▊                       | 2/10 [00:00<00:00, 16.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████▊                       | 2/10 [00:00<00:00, 16.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Negative (67%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[Positive (52%)]] --> [[Negative (74%)]]\n",
      "\n",
      "[[effective]] but too-tepid biopic\n",
      "\n",
      "[[effdctive]] but too-tepid biopic\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  30%|████████▋                    | 3/10 [00:00<00:00,  7.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  40%|███████████▌                 | 4/10 [00:00<00:00,  8.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 3 / 4:  40%|███████████▌                 | 4/10 [00:00<00:00,  8.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[Negative (73%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 4 / 5:  50%|██████████████▌              | 5/10 [00:00<00:00,  9.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 4 / 5:  60%|█████████████████▍           | 6/10 [00:00<00:00, 10.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 5 / 6:  60%|█████████████████▍           | 6/10 [00:00<00:00, 10.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[Negative (83%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "[[Positive (66%)]] --> [[Negative (73%)]]\n",
      "\n",
      "[[offers]] that rare combination of entertainment and education .\n",
      "\n",
      "[[offdrs]] that rare combination of entertainment and education .\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 5 / 7:  70%|████████████████████▎        | 7/10 [00:01<00:00,  6.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 5 / 7:  80%|███████████████████████▏     | 8/10 [00:01<00:00,  6.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 6 / 8:  80%|███████████████████████▏     | 8/10 [00:01<00:00,  6.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 7 / 9:  90%|██████████████████████████   | 9/10 [00:01<00:00,  7.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 7 / 9: 100%|████████████████████████████| 10/10 [00:01<00:00,  5.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 7 / 10: 100%|███████████████████████████| 10/10 [00:01<00:00,  5.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[Positive (51%)]] --> [[Negative (86%)]]\n",
      "\n",
      "take [[care]] of my cat offers a refreshingly different slice of asian cinema .\n",
      "\n",
      "take [[caTre]] of my cat offers a refreshingly different slice of asian cinema .\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 3      |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 7      |\n",
      "| Original accuracy:            | 30.0%  |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "| Average perturbed word %:     | 15.06% |\n",
      "| Average num. words per input: | 19.5   |\n",
      "| Avg num queries:              | 219.0  |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import Pruthi2019\n",
    "attack_tensor(Pruthi2019,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c740771",
   "metadata": {},
   "source": [
    "## Pso Zang 2020 (doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae59da22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Downloading https://textattack.s3.amazonaws.com/transformations/hownet/word_candidates_sense.pkl.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                      | 0.00/8.39M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▋                                                                             | 68.6k/8.39M [00:00<00:19, 430kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|██▊                                                                            | 295k/8.39M [00:00<00:08, 975kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|██████▍                                                                       | 695k/8.39M [00:00<00:03, 1.98MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|████████████▏                                                                | 1.32M/8.39M [00:00<00:02, 3.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████████████████▋                                                    | 2.69M/8.39M [00:00<00:00, 6.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|█████████████████████████████████████                                        | 4.04M/8.39M [00:00<00:00, 8.73MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████████████████████████████▊                            | 5.31M/8.39M [00:00<00:00, 9.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|████████████████████████████████████████████████████████████▉                | 6.64M/8.39M [00:00<00:00, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8.39M/8.39M [00:01<00:00, 7.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "textattack: Copying C:\\Users\\mattl\\.cache\\textattack\\tmp91dpnw2f.zip to C:\\Users\\mattl/.cache/textattack\\transformations/hownet/word_candidates_sense.pkl.\n",
      "textattack: Successfully saved transformations/hownet/word_candidates_sense.pkl to cache.\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████                    | 2/10 [59:50<3:59:22, 1795.33s/it]\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████                    | 2/10 [35:49<2:23:18, 1074.79s/it]\n",
      "  2%|█▌                                                                        | 83.8M/3.87G [34:28<25:59:12, 40.5kB/s]\n",
      "textattack: Unknown if model of class <class 'keras.engine.sequential.Sequential'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): ParticleSwarmOptimization(\n",
      "    (pop_size):  60\n",
      "    (max_iters):  20\n",
      "    (post_turn_check):  True\n",
      "    (max_turn_retries):  20\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapHowNet(\n",
      "    (max_candidates):  -1\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): RepeatModification\n",
      "    (1): StopwordModification\n",
      "    (2): InputColumnModification(\n",
      "        (matching_column_labels):  ['premise', 'hypothesis']\n",
      "        (columns_to_ignore):  {'premise'}\n",
      "      )\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10%|██▉                          | 1/10 [00:00<00:00, 17.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[Negative (74%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████▊                       | 2/10 [00:00<00:00, 17.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Negative (67%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [12:58<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'upos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextattack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattack_recipes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PSOZang2020\n\u001b[1;32m----> 2\u001b[0m \u001b[43mattack_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPSOZang2020\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtext_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m, in \u001b[0;36mattack_tensor\u001b[1;34m(attack_recipe, model_wrapper, text_data)\u001b[0m\n\u001b[0;32m      2\u001b[0m attack \u001b[38;5;241m=\u001b[39m attack_recipe\u001b[38;5;241m.\u001b[39mbuild(model_wrapper)\n\u001b[0;32m      4\u001b[0m attacker \u001b[38;5;241m=\u001b[39m Attacker(attack,text_data)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mattacker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:441\u001b[0m, in \u001b[0;36mAttacker.attack_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attack_parallel()\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39msilent:\n\u001b[0;32m    444\u001b[0m     logger\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mINFO)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:170\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack\u001b[38;5;241m.\u001b[39mattack(example, ground_truth_output)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, SkippedAttackResult) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mattack_n\n\u001b[0;32m    173\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, SuccessfulAttackResult)\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mnum_successful_examples\n\u001b[0;32m    176\u001b[0m ):\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m worklist_candidates:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:168\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m     example\u001b[38;5;241m.\u001b[39mattack_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mlabel_names\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:450\u001b[0m, in \u001b[0;36mAttack.attack\u001b[1;34m(self, example, ground_truth_output)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SkippedAttackResult(goal_function_result)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 450\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoal_function_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:398\u001b[0m, in \u001b[0;36mAttack._attack\u001b[1;34m(self, initial_result)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_attack\u001b[39m(\u001b[38;5;28mself\u001b[39m, initial_result):\n\u001b[0;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the ``SearchMethod`` to perturb the ``AttackedText`` stored in\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m    ``initial_result``.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m            or ``MaximizedAttackResult``.\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     final_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_cache()\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_result\u001b[38;5;241m.\u001b[39mgoal_status \u001b[38;5;241m==\u001b[39m GoalFunctionResultStatus\u001b[38;5;241m.\u001b[39mSUCCEEDED:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\search_methods\\search_method.py:36\u001b[0m, in \u001b[0;36mSearchMethod.__call__\u001b[1;34m(self, initial_result)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter_transformations\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch Method must have access to filter_transformations method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m     )\n\u001b[1;32m---> 36\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# ensure that the number of queries for this GoalFunctionResult is up-to-date\u001b[39;00m\n\u001b[0;32m     38\u001b[0m result\u001b[38;5;241m.\u001b[39mnum_queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoal_function\u001b[38;5;241m.\u001b[39mnum_queries\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\search_methods\\particle_swarm_optimization.py:217\u001b[0m, in \u001b[0;36mParticleSwarmOptimization.perform_search\u001b[1;34m(self, initial_result)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, initial_result):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_over \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m     population \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# Initialize  up velocities of each word for each population\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     v_init \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_max, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_max, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop_size)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\search_methods\\particle_swarm_optimization.py:203\u001b[0m, in \u001b[0;36mParticleSwarmOptimization._initialize_population\u001b[1;34m(self, initial_result, pop_size)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_population\u001b[39m(\u001b[38;5;28mself\u001b[39m, initial_result, pop_size):\n\u001b[0;32m    195\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m    Initialize a population of size `pop_size` with `initial_result`\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m        population as `list[PopulationMember]`\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m     best_neighbors, prob_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best_neighbors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_result\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     population \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pop_size):\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;66;03m# Mutation step\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\search_methods\\particle_swarm_optimization.py:160\u001b[0m, in \u001b[0;36mParticleSwarmOptimization._get_best_neighbors\u001b[1;34m(self, current_result, original_result)\u001b[0m\n\u001b[0;32m    158\u001b[0m current_text \u001b[38;5;241m=\u001b[39m current_result\u001b[38;5;241m.\u001b[39mattacked_text\n\u001b[0;32m    159\u001b[0m neighbors_list \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(current_text\u001b[38;5;241m.\u001b[39mwords))]\n\u001b[1;32m--> 160\u001b[0m transformed_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moriginal_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattacked_text\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m transformed_text \u001b[38;5;129;01min\u001b[39;00m transformed_texts:\n\u001b[0;32m    164\u001b[0m     diff_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28miter\u001b[39m(transformed_text\u001b[38;5;241m.\u001b[39mattack_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnewly_modified_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    166\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:305\u001b[0m, in \u001b[0;36mAttack.get_transformations\u001b[1;34m(self, current_text, original_text, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m     transformed_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_cache[cache_key])\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 305\u001b[0m     transformed_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_transformations_uncached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mhashable(cache_key):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_cache[cache_key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(transformed_texts)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:273\u001b[0m, in \u001b[0;36mAttack._get_transformations_uncached\u001b[1;34m(self, current_text, original_text, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_transformations_uncached\u001b[39m(\u001b[38;5;28mself\u001b[39m, current_text, original_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    264\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies ``self.transformation`` to ``text``, then filters the list\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    of possible transformations through the applicable constraints.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m        A filtered list of transformations where each transformation matches the constraints\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     transformed_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpre_transformation_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_transformation_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformed_texts\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\transformations\\transformation.py:57\u001b[0m, in \u001b[0;36mTransformation.__call__\u001b[1;34m(self, current_text, pre_transformation_constraints, indices_to_modify, shifted_idxs, return_indices)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_indices:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indices_to_modify\n\u001b[1;32m---> 57\u001b[0m transformed_texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_transformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_to_modify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m transformed_texts:\n\u001b[0;32m     59\u001b[0m     text\u001b[38;5;241m.\u001b[39mattack_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_transformation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\transformations\\word_swaps\\word_swap_hownet.py:68\u001b[0m, in \u001b[0;36mWordSwapHowNet._get_transformations\u001b[1;34m(self, current_text, indices_to_modify)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices_to_modify:\n\u001b[0;32m     67\u001b[0m     word_to_replace \u001b[38;5;241m=\u001b[39m current_text\u001b[38;5;241m.\u001b[39mwords[i]\n\u001b[1;32m---> 68\u001b[0m     word_to_replace_pos \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_of_word_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     replacement_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_replacement_words(\n\u001b[0;32m     70\u001b[0m         word_to_replace, word_to_replace_pos\n\u001b[0;32m     71\u001b[0m     )\n\u001b[0;32m     72\u001b[0m     transformed_texts_idx \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\shared\\attacked_text.py:141\u001b[0m, in \u001b[0;36mAttackedText.pos_of_word_index\u001b[1;34m(self, desired_word_idx)\u001b[0m\n\u001b[0;32m    139\u001b[0m     textattack\u001b[38;5;241m.\u001b[39mshared\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mflair_tag(sentence)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos_tags \u001b[38;5;241m=\u001b[39m sentence\n\u001b[1;32m--> 141\u001b[0m flair_word_list, flair_pos_list \u001b[38;5;241m=\u001b[39m \u001b[43mtextattack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzip_flair_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pos_tags\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word_idx, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwords):\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    147\u001b[0m         word \u001b[38;5;129;01min\u001b[39;00m flair_word_list\n\u001b[0;32m    148\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword absent in flair returned part-of-speech tags\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\shared\\utils\\strings.py:245\u001b[0m, in \u001b[0;36mzip_flair_result\u001b[1;34m(pred, tag_type)\u001b[0m\n\u001b[0;32m    243\u001b[0m word_list\u001b[38;5;241m.\u001b[39mappend(token\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tag_type:\n\u001b[1;32m--> 245\u001b[0m     pos_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mannotation_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_value)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tag_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    247\u001b[0m     pos_list\u001b[38;5;241m.\u001b[39mappend(token\u001b[38;5;241m.\u001b[39mget_label(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'upos'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████▊                       | 2/10 [00:16<01:06,  8.32s/it]"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import PSOZang2020\n",
    "attack_tensor(PSOZang2020,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32403cce",
   "metadata": {},
   "source": [
    "## PWWS Ren 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d18c676",
   "metadata": {},
   "source": [
    "This algorithim is another word swap algorithim that goes for synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d72e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mattl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "textattack: Unknown if model of class <class 'keras.engine.sequential.Sequential'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  weighted-saliency\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapWordNet\n",
      "  (constraints): \n",
      "    (0): RepeatModification\n",
      "    (1): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10%|██▉                          | 1/10 [00:00<00:00, 16.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[Negative (74%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  20%|█████▊                       | 2/10 [00:00<00:00, 15.62it/s]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████▊                       | 2/10 [00:00<00:00, 15.27it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Negative (67%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[Positive (52%)]] --> [[Negative (53%)]]\n",
      "\n",
      "[[effective]] but too-tepid biopic\n",
      "\n",
      "[[effectual]] but too-tepid biopic"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  30%|████████▋                    | 3/10 [00:00<00:00,  9.32it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  40%|███████████▌                 | 4/10 [00:00<00:00, 10.58it/s]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 3 / 4:  40%|███████████▌                 | 4/10 [00:00<00:00, 10.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[Negative (73%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 4 / 5:  50%|██████████████▌              | 5/10 [00:00<00:00, 11.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 4 / 5:  60%|█████████████████▍           | 6/10 [00:00<00:00, 12.19it/s]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 5 / 6:  60%|█████████████████▍           | 6/10 [00:00<00:00, 12.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[Negative (83%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "[[Positive (66%)]] --> [[Negative (77%)]]\n",
      "\n",
      "[[offers]] that rare combination of entertainment and education .\n",
      "\n",
      "[[provide]] that rare combination of entertainment and education .\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 5 / 7:  70%|████████████████████▎        | 7/10 [00:00<00:00,  7.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 5 / 7:  80%|███████████████████████▏     | 8/10 [00:00<00:00,  8.18it/s]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 6 / 8:  80%|███████████████████████▏     | 8/10 [00:00<00:00,  8.16it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 7 / 9:  90%|██████████████████████████   | 9/10 [00:01<00:00,  8.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 7 / 9: 100%|████████████████████████████| 10/10 [00:01<00:00,  5.82it/s]\u001b[A\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 7 / 10: 100%|███████████████████████████| 10/10 [00:01<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[Positive (51%)]] --> [[Negative (70%)]]\n",
      "\n",
      "take care of my cat [[offers]] a refreshingly different slice of asian cinema .\n",
      "\n",
      "take care of my cat [[offering]] a refreshingly different slice of asian cinema .\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 7 / 10: 100%|███████████████████████████| 10/10 [00:01<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 3      |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 7      |\n",
      "| Original accuracy:            | 30.0%  |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "| Average perturbed word %:     | 15.06% |\n",
      "| Average num. words per input: | 19.5   |\n",
      "| Avg num queries:              | 72.0   |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import PWWSRen2019\n",
    "attack_tensor(PWWSRen2019,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa97b274",
   "metadata": {},
   "source": [
    "## Seq2sick Cheng 2018 Blackbox (doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fcbc03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'keras.engine.sequential.Sequential'> compatible with goal function <class 'textattack.goal_functions.text.non_overlapping_output.NonOverlappingOutput'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  unk\n",
      "  )\n",
      "  (goal_function):  NonOverlappingOutput\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): LevenshteinEditDistance(\n",
      "        (max_edit_distance):  30\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "split() missing 1 required positional argument: 'split_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\shared\\utils\\strings.py:35\u001b[0m, in \u001b[0;36mwords_from_text\u001b[1;34m(s, words_to_ignore)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[\u001b[39;49m\u001b[38;5;130;43;01m\\u4e00\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;130;43;01m\\u9FFF\u001b[39;49;00m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     36\u001b[0m         seg_list \u001b[38;5;241m=\u001b[39m jieba\u001b[38;5;241m.\u001b[39mcut(s, cut_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\re.py:201\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03ma Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextattack\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattack_recipes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Seq2SickCheng2018BlackBox\n\u001b[1;32m----> 2\u001b[0m \u001b[43mattack_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSeq2SickCheng2018BlackBox\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtext_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m, in \u001b[0;36mattack_tensor\u001b[1;34m(attack_recipe, model_wrapper, text_data)\u001b[0m\n\u001b[0;32m      2\u001b[0m attack \u001b[38;5;241m=\u001b[39m attack_recipe\u001b[38;5;241m.\u001b[39mbuild(model_wrapper)\n\u001b[0;32m      4\u001b[0m attacker \u001b[38;5;241m=\u001b[39m Attacker(attack,text_data)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mattacker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:441\u001b[0m, in \u001b[0;36mAttacker.attack_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attack_parallel()\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39msilent:\n\u001b[0;32m    444\u001b[0m     logger\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mINFO)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:170\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack\u001b[38;5;241m.\u001b[39mattack(example, ground_truth_output)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, SkippedAttackResult) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mattack_n\n\u001b[0;32m    173\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, SuccessfulAttackResult)\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mnum_successful_examples\n\u001b[0;32m    176\u001b[0m ):\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m worklist_candidates:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attacker.py:168\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m     example\u001b[38;5;241m.\u001b[39mattack_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mlabel_names\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\attack.py:444\u001b[0m, in \u001b[0;36mAttack.attack\u001b[1;34m(self, example, ground_truth_output)\u001b[0m\n\u001b[0;32m    439\u001b[0m     example \u001b[38;5;241m=\u001b[39m AttackedText(example)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    442\u001b[0m     ground_truth_output, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    443\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`ground_truth_output` must either be `str` or `int`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 444\u001b[0m goal_function_result, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoal_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_attack_example\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_output\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m goal_function_result\u001b[38;5;241m.\u001b[39mgoal_status \u001b[38;5;241m==\u001b[39m GoalFunctionResultStatus\u001b[38;5;241m.\u001b[39mSKIPPED:\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SkippedAttackResult(goal_function_result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:68\u001b[0m, in \u001b[0;36mGoalFunction.init_attack_example\u001b[1;34m(self, attacked_text, ground_truth_output)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mground_truth_output \u001b[38;5;241m=\u001b[39m ground_truth_output\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 68\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattacked_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_skip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, _\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:79\u001b[0m, in \u001b[0;36mGoalFunction.get_result\u001b[1;34m(self, attacked_text, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, attacked_text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A helper method that queries ``self.get_results`` with a single\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m    ``AttackedText`` object.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     results, search_over \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mattacked_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     result \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, search_over\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:99\u001b[0m, in \u001b[0;36mGoalFunction.get_results\u001b[1;34m(self, attacked_text_list, check_skip)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attacked_text, raw_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(attacked_text_list, model_outputs):\n\u001b[0;32m     98\u001b[0m     displayed_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_displayed_output(raw_output)\n\u001b[1;32m---> 99\u001b[0m     goal_status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_goal_status\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattacked_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_skip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_skip\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     goal_function_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_score(raw_output, attacked_text)\n\u001b[0;32m    103\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_goal_function_result_type()(\n\u001b[0;32m    105\u001b[0m             attacked_text,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m         )\n\u001b[0;32m    113\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:117\u001b[0m, in \u001b[0;36mGoalFunction._get_goal_status\u001b[1;34m(self, model_output, attacked_text, check_skip)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_goal_status\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_output, attacked_text, check_skip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 117\u001b[0m     should_skip \u001b[38;5;241m=\u001b[39m check_skip \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_skip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattacked_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_skip:\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m GoalFunctionResultStatus\u001b[38;5;241m.\u001b[39mSKIPPED\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:131\u001b[0m, in \u001b[0;36mGoalFunction._should_skip\u001b[1;34m(self, model_output, attacked_text)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_should_skip\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_output, attacked_text):\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_goal_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattacked_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\text\\non_overlapping_output.py:31\u001b[0m, in \u001b[0;36mNonOverlappingOutput._is_goal_complete\u001b[1;34m(self, model_output, _)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_goal_complete\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_output, _):\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mground_truth_output\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\text\\non_overlapping_output.py:34\u001b[0m, in \u001b[0;36mNonOverlappingOutput._get_score\u001b[1;34m(self, model_output, _)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_score\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_output, _):\n\u001b[1;32m---> 34\u001b[0m     num_words_diff \u001b[38;5;241m=\u001b[39m \u001b[43mword_difference_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mground_truth_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_words_diff \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\text\\non_overlapping_output.py:50\u001b[0m, in \u001b[0;36mword_difference_score\u001b[1;34m(s1, s2)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_difference_score\u001b[39m(s1, s2):\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the number of words that are non-overlapping between s1 and\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    s2.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     s1_words \u001b[38;5;241m=\u001b[39m \u001b[43mget_words_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     s2_words \u001b[38;5;241m=\u001b[39m get_words_cached(s2)\n\u001b[0;32m     52\u001b[0m     min_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(s1_words), \u001b[38;5;28mlen\u001b[39m(s2_words))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\goal_functions\\text\\non_overlapping_output.py:43\u001b[0m, in \u001b[0;36mget_words_cached\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_words_cached\u001b[39m(s):\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mwords_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textattack\\shared\\utils\\strings.py:41\u001b[0m, in \u001b[0;36mwords_from_text\u001b[1;34m(s, words_to_ignore)\u001b[0m\n\u001b[0;32m     39\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(s\u001b[38;5;241m.\u001b[39msplit())\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     43\u001b[0m homos \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m˗৭Ȣ𝟕бƼᏎƷᒿlO`ɑЬϲԁе𝚏ɡհіϳ𝒌ⅼｍոорԛⲅѕ𝚝սѵԝ×уᴢ\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     44\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-_*@\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: split() missing 1 required positional argument: 'split_size'"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import Seq2SickCheng2018BlackBox\n",
    "attack_tensor(Seq2SickCheng2018BlackBox,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14671944",
   "metadata": {},
   "source": [
    "## Text Bugger Li 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6d8a43",
   "metadata": {},
   "source": [
    "This is a rather malicious algorithim that causes failures in deep learning algorithims. What makes is particularly malicious is the replacement looks identical to human eyes so it is incredibly difficult to tell when the data has been poisoned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb488984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'keras.engine.sequential.Sequential'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  CompositeTransformation(\n",
      "    (0): WordSwapRandomCharacterInsertion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (1): WordSwapRandomCharacterDeletion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (2): WordSwapNeighboringCharacterSwap(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (3): WordSwapHomoglyphSwap\n",
      "    (4): WordSwapEmbedding(\n",
      "        (max_candidates):  5\n",
      "        (embedding):  WordEmbedding\n",
      "      )\n",
      "    )\n",
      "  (constraints): \n",
      "    (0): UniversalSentenceEncoder(\n",
      "        (metric):  angular\n",
      "        (threshold):  0.8\n",
      "        (window_size):  inf\n",
      "        (skip_text_shorter_than_window):  False\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10%|██▉                          | 1/10 [00:00<00:00, 16.13it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "[[Negative (74%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  20%|█████▊                       | 2/10 [00:00<00:00, 17.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:  20%|█████▊                       | 2/10 [00:00<00:00, 16.67it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "[[Negative (67%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  30%|████████▋                    | 3/10 [00:05<00:13,  1.94s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "[[Positive (52%)]] --> [[Negative (52%)]]\n",
      "\n",
      "effective but [[too-tepid]] biopic\n",
      "\n",
      "effective but [[too˗tepid]] biopic\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 2 / 3:  40%|███████████▌                 | 4/10 [00:05<00:08,  1.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 3 / 4:  40%|███████████▌                 | 4/10 [00:05<00:08,  1.47s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "[[Negative (73%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "if you sometimes like to go to the movies to have fun , wasabi is a good place to start .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 4 / 5:  50%|██████████████▌              | 5/10 [00:05<00:05,  1.18s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 4 / 5:  60%|█████████████████▍           | 6/10 [00:05<00:03,  1.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 5 / 6:  60%|█████████████████▍           | 6/10 [00:05<00:03,  1.00it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "[[Negative (83%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "the film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 5 / 7:  70%|████████████████████▎        | 7/10 [00:06<00:02,  1.14it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "[[Positive (66%)]] --> [[Negative (59%)]]\n",
      "\n",
      "offers that rare combination of entertainment and [[education]] .\n",
      "\n",
      "offers that rare combination of entertainment and [[eduϲation]] .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 5 / 7:  80%|███████████████████████▏     | 8/10 [00:06<00:01,  1.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 6 / 8:  80%|███████████████████████▏     | 8/10 [00:06<00:01,  1.29it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 7 / 9:  90%|██████████████████████████   | 9/10 [00:06<00:00,  1.44it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "[[Negative (82%)]] --> [[[SKIPPED]]]\n",
      "\n",
      "steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 7 / 9: 100%|████████████████████████████| 10/10 [00:06<00:00,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 7 / 10: 100%|███████████████████████████| 10/10 [00:06<00:00,  1.56it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "[[Positive (51%)]] --> [[Negative (58%)]]\n",
      "\n",
      "take care of my cat offers a [[refreshingly]] different slice of asian cinema .\n",
      "\n",
      "take care of my cat offers a [[refreshiոgly]] different slice of asian cinema .\n",
      "\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 3      |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 7      |\n",
      "| Original accuracy:            | 30.0%  |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "| Average perturbed word %:     | 15.06% |\n",
      "| Average num. words per input: | 19.5   |\n",
      "| Avg num queries:              | 22.67  |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from textattack.attack_recipes import TextBuggerLi2018\n",
    "attack_tensor(TextBuggerLi2018,model_wrapper,text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56090ed",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f03c2",
   "metadata": {},
   "source": [
    "In addition to the attacks that worked with the Sklearn models, there are more attacks that were successfully implemented against a TensorFlow LSTM model. Notably while the attacks could not attack all the data, the attacks that were successful generally all managed to successfully turn the classification into a false positive or false negative. Compared to sklearn, Tensorflow seems to be more robust but has a particularly nasty algorithim that can be used against it. In order of most effective to least effective the models are the following:\n",
    "1. Text Bugger Li 2018 (Insidious poisoning, 3 success, 7 skipped)\n",
    "2. TextFoolerJin2019 = Iga Wang 2019 = Input Reduction = Pruthi2019 (3 success, 7 skipped)\n",
    "3. Checklist 2020 (3 fail, 7 skipped)\n",
    "4. Kuleshov 2017 (all skipped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
